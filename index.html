<!DOCTYPE html>
<html>
<head>
    <link rel="stylesheet" href="style.css">
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/hand-pose-detection"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands"></script>
</head>
<body>
    <div class="container">
        <video id="webcam" autoplay playsinline></video>
        <canvas id="output-canvas"></canvas>
    </div>

    <button id="start-camera">Start Camera</button>

    <script>
        const video = document.getElementById('webcam');
        const canvas = document.getElementById('output-canvas');
        const ctx = canvas.getContext('2d');
        const btn = document.getElementById('start-camera');
        let detector;

        async function initDetector() {
            const model = handPoseDetection.SupportedModels.MediaPipeHands;
            const detectorConfig = {
                runtime: 'mediapipe',
                solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/hands'
            };
            detector = await handPoseDetection.createDetector(model, detectorConfig);
        }

        async function detectHands() {
            if (detector && video.readyState >= 2) {
                // The AI detects based on the video source
                const hands = await detector.estimateHands(video); 
                
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                
                if (hands.length > 0) {
                    // Calculate the scaling ratio between video source and screen display
                    const displaySize = video.getBoundingClientRect();
                    const scaleX = displaySize.width / video.videoWidth;
                    const scaleY = displaySize.height / video.videoHeight;

                    hands.forEach(hand => {
                        hand.keypoints.forEach(keypoint => {
                            ctx.beginPath();
                            // Multiply raw coordinates by the scale to align with screen pixels
                            ctx.arc(keypoint.x * scaleX, keypoint.y * scaleY, 5, 0, 2 * Math.PI);
                            ctx.fillStyle = "red";
                            ctx.fill();
                        });
                    });
                }
            }
            requestAnimationFrame(detectHands);
        }

        btn.addEventListener('click', async () => {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;

                await initDetector();
                
                video.onloadedmetadata = () => {
                    const displaySize = video.getBoundingClientRect();
                    // Set canvas to match the CSS visual size exactly
                    canvas.width = displaySize.width;
                    canvas.height = displaySize.height;
                    detectHands();
                };
            } catch (error) {
                console.error("Camera error:", error);
            }
        });
    </script> 
</body>
</html>